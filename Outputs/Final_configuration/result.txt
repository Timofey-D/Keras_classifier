Final configuration: with regularizer L2 = 0.001 and dropout = 0.5

Accuracy = 70.28%
Loss = 2.2616

              precision    recall  f1-score   support

           0       0.75      0.69      0.72        13
           1       0.77      0.65      0.71        26
           2       0.88      0.74      0.80        19
           3       0.50      0.47      0.48        15
           4       0.67      0.80      0.73        15
           5       0.91      0.87      0.89        23
           6       0.62      0.53      0.57        15
           7       0.86      0.82      0.84        22
           8       0.62      0.73      0.67        11
           9       0.71      0.77      0.74        22
          10       0.61      0.67      0.64        21
          11       0.65      0.61      0.63        18
          12       0.88      0.83      0.86        18
          13       0.58      0.44      0.50        16
          14       0.75      0.29      0.41        21
          15       0.67      0.43      0.52        14
          16       0.58      0.74      0.65        19
          17       0.73      0.88      0.80        25
          18       0.61      0.65      0.63        17
          19       0.69      0.75      0.72        24
          20       0.67      0.84      0.74        19
          21       0.33      0.25      0.29        12
          22       0.73      0.86      0.79        22
          23       0.52      0.71      0.60        17
          24       0.95      0.86      0.90        22
          25       0.68      0.75      0.71        20
          26       0.76      0.86      0.81        22

    accuracy                           0.70       508
   macro avg       0.69      0.68      0.68       508
weighted avg       0.71      0.70      0.70       508
